import logging
import os
import shutil

from sqlalchemy.orm import Session

from config import Config
from errors import WorkflowError
from models.api.dag_model import DAGRequest
from models.db.flow import Flow as DBFlow
from models.domain.mapper import flow_api2domain, flow_db2domain, flow_domain2db, task_edge_domain2db, flow_domain2api

logger = logging.getLogger()


class FlowDefinitionService:
    def __init__(self, meta_db: Session, airflow_db: Session):
        self.meta_db = meta_db
        self.airflow_db = airflow_db

    def find_existing_flow(self, dag: DAGRequest):
        return (
            self.meta_db.query(DBFlow)
            # .filter((DBFlow.id == self.dag.id) | (DBFlow.name == self.dag.name))
            .filter(DBFlow.name == dag.name)
            .first()
        )

    def save_dag(self, dag: DAGRequest):
        existing = self.find_existing_flow(dag)

        if existing:
            raise WorkflowError("DAG already exists")
        else:
            logger.info(f"ğŸ†• DAG ì‹ ê·œ ë“±ë¡: {dag.name}")
            domain_flow = flow_api2domain(dag)
            db_flow = flow_domain2db(domain_flow, self.airflow_db)
            self.meta_db.add(db_flow)
            self.meta_db.commit()

    def update_dag(self, origin_dag_id: str, new_dag: DAGRequest):
        # 0. ê¸°ì¡´ Flow ì¡°íšŒ
        origin_flow = (
            self.meta_db.query(DBFlow)
            .filter(DBFlow.id == origin_dag_id)
            .first()
        )
        if origin_flow is None:
            raise WorkflowError(f"DAG ({origin_dag_id}) ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # 1. ë³€í™˜
        new_flow = flow_api2domain(new_dag)
        # ì´ë¦„ì´ ë°”ë€ ê²½ìš° â†’ ì¤‘ë³µ í™•ì¸
        if new_flow.name != origin_flow.name:
            duplicate = (
                self.meta_db.query(DBFlow)
                .filter(DBFlow.name == new_flow.name, DBFlow.id != origin_flow.id)
                .first()
            )
            if duplicate:
                raise WorkflowError(f"Flow ì´ë¦„ '{new_flow.name}' ì€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
        # 3. í•„ë“œ ê°±ì‹ 
        origin_flow.name = new_flow.name
        origin_flow.description = new_flow.description
        origin_flow.schedule = new_flow.scheduled
        origin_flow.hash = hash(new_flow)
        origin_flow.file_hash = new_flow.file_hash

        origin_flow.tasks.clear()
        origin_flow.edges.clear()

        origin_flow.tasks, origin_flow.edges = task_edge_domain2db(origin_flow, new_flow.edges)

        try:
            self.meta_db.commit()
        except Exception as e:
            self.meta_db.rollback()
            msg = f"âŒ DAG ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}"
            logger.error(msg)
            raise WorkflowError(msg)

    def get_active_flows(self) -> list[DBFlow]:
        return self.meta_db.query(DBFlow).filter(DBFlow.is_deleted == False).all()

    def get_all_flows(self) -> list[DBFlow]:
        return self.meta_db.query(DBFlow).all()

    def get_dag_list(self, is_deleted=False):
        if is_deleted:
            flows = self.get_all_flows()
        else:
            flows = self.get_active_flows()
        return [flow_domain2api(flow_db2domain(dbflow)) for dbflow in flows]

    def get_dag(self, dag_id):
        flow = self.meta_db.query(DBFlow).filter(DBFlow.id == dag_id).first()
        if flow is None:
            raise WorkflowError(f"DAG ({dag_id}) ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return flow_domain2api(flow_db2domain(flow))

    def delete_dag_temporary(self, dag_id: str):
        flow = self.meta_db.query(DBFlow).filter(DBFlow.id == dag_id).first()
        if not flow:
            raise WorkflowError(f"Flow({dag_id}) not found")

        delete_dag_file(flow.dag_id)

        flow.is_deleted = True
        flow.file_hash = None
        self.meta_db.commit()
        logger.info(f"ğŸ•’ DAG ì„ì‹œ ì‚­ì œë¨ (DB ë³´ê´€): {flow.name}")

    def delete_dag_permanently(self, dag_id: str):
        flow = self.meta_db.query(DBFlow).filter(DBFlow.id == dag_id).first()
        if not flow:
            raise WorkflowError(f"Flow({dag_id}) not found")

        delete_dag_file(flow.dag_id)

        self.meta_db.delete(flow)
        self.meta_db.commit()
        logger.info(f"ğŸ’¥ DAG ì˜êµ¬ ì‚­ì œë¨: {flow.name}")

    def restore_deleted_dag(self, dag_id: str):
        flow = self.meta_db.query(DBFlow).filter(DBFlow.id == dag_id).first()
        if not flow or not flow.is_deleted:
            raise WorkflowError(f"Flow({dag_id}) not found")

        flow.is_deleted = False
        flow.file_hash = flow_db2domain(flow).file_hash

        self.meta_db.commit()
        logger.info(f"â™»ï¸ DAG ë³µêµ¬ë¨: {flow.name}")


def delete_dag_file(dag_id: str):
    dag_dir_path = os.path.join(Config.DAG_DIR, dag_id)
    dag_file_path = os.path.join(dag_dir_path, "dag.py")
    if os.path.exists(dag_file_path):
        os.remove(dag_file_path)
        logger.info(f"ğŸ—‘ DAG íŒŒì¼ ì‚­ì œë¨: {dag_file_path}")
    else:
        logger.warning(f"âš ï¸ DAG íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {dag_file_path}")
    # ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹œë„
    try:
        shutil.rmtree(dag_dir_path)
        logger.info(f"ğŸ“‚ DAG ë””ë ‰í† ë¦¬ ì‚­ì œë¨: {dag_dir_path}")
    except FileNotFoundError:
        logger.warning(f"âš ï¸ DAG ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {dag_dir_path}")
    except Exception as e:
        logger.error(f"âŒ DAG ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {e}")
