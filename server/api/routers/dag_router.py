import base64
import logging
import os.path
import traceback
from typing import List

from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.orm import Session

from api.models.api_model import api_response_wrapper, APIResponse
from api.models.dag_model import DAGRequest, DAGResponse
from api.render_template import render_dag_script
from config import Config
from core.database import get_db
from models.edge import Edge
from models.flow import Flow
from models.function_library import FunctionLibrary
from models.task import Task
from models.task_input import TaskInput
from models.task_ui import TaskUI
from utils.udf_validator import get_validated_inputs

logger = logging.getLogger()

# ì›Œí¬í”Œë¡œìš° ë¸”ë£¨í”„ë¦°íŠ¸ ìƒì„±
router = APIRouter(
    prefix="/dag",
    tags=["Dag"],
)


@router.post("",
             response_model=APIResponse[DAGResponse],
             )
@api_response_wrapper
async def create_dag(dag: DAGRequest, db: Session = Depends(get_db)):
    """DAG ìƒì„± ë° DB ì— ì €ì¥"""
    logger.info(f"Request Data: {dag}")
    dag_id = "dag_" + base64.urlsafe_b64encode(dag.name.encode()).rstrip(b'=').decode('ascii')
    dag_file_path = os.path.join(Config.DAG_DIR, f"{dag_id}.py")
    try:
        with db.begin():
            # í•œ ë²ˆì˜ ì¿¼ë¦¬ë¡œ ì¡°íšŒ
            udf_functions: {str, FunctionLibrary} = {
                udf.id: udf
                for udf in db.query(FunctionLibrary)
                .filter(FunctionLibrary.id.in_([node.data.function_id for node in dag.nodes]))
                .all()
            }

            # ì—†ëŠ” UDF ì°¾ê¸°
            missing_udfs = [node for node in dag.nodes
                            if node.data.function_id not in udf_functions.keys()]

            # UDFê°€ ëˆ„ë½ë˜ì—ˆë‹¤ë©´ ì—ëŸ¬ ë°˜í™˜
            if missing_udfs:
                logger.info(f"UDFs not found: {missing_udfs}")
                return {"message": f"UDFs not found: {missing_udfs}"}

            # Flow ìƒì„±
            flow = Flow(id=dag_id, name=dag.name, description=dag.description)
            db.add(flow)
            db.flush()

            # tasks ìƒì„±
            id_to_variable_id = {}
            for i, node in enumerate(dag.nodes):
                variable_id = f"task_{i}"
                id_to_variable_id[node.id] = variable_id
            tasks = {}
            for i, node in enumerate(dag.nodes):
                # ì²« ë²ˆì§¸ ë…¸ë“œì¸ì§€ í™•ì¸
                is_first_task = all(edge.target != node.id for edge in dag.edges)

                task_inputs = get_validated_inputs(udf_functions[node.data.function_id].inputs, node.data.inputs)
                if not is_first_task:
                    # ë¶€ëª¨ ë…¸ë“œë¥¼ ì°¾ì•„ì„œ before_task_id ì„¤ì •
                    task_inputs.append({
                        "key": "before_task_ids",
                        "value": [id_to_variable_id[edge.source] for edge in dag.edges if edge.target == node.id],
                        "type": "string"
                    })
                task_data = Task(
                    variable_id=id_to_variable_id[node.id],
                    flow_id=flow.id,
                    function_id=node.data.function_id,
                    decorator="file_decorator",
                )
                for inp in task_inputs:
                    task_data.inputs.append(TaskInput(
                        key=inp.get("key"),
                        type=inp.get("type"),
                        value=inp.get("value"),
                    ))
                logger.info(f"Task Data: {task_data}")
                task_data.task_ui = TaskUI(type=node.type,
                                           position=node.position,
                                           style=node.style, )
                tasks[node.id] = task_data

            # edge ìƒì„±
            edges = []
            for edge in dag.edges:
                edges.append(Edge(flow_id=flow.id,
                                  from_task=tasks[edge.source],
                                  to_task=tasks[edge.target]
                                  ))

            # save dag metadata to DB
            db.add_all(tasks.values())
            db.add_all(edges)
            db.flush()

            # write dag
            with open(dag_file_path, 'w') as dag_file:
                dag_file.write(render_dag_script(dag_id, tasks.values(), edges))
            db.commit()
        return DAGResponse.from_dag(flow)
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logger.error(traceback.format_exc())
        db.rollback()
        logger.warning(f"ğŸ”„ ë©”íƒ€ë°ì´í„° ë¡¤ë°±")

        # âœ… íŒŒì¼ ì €ì¥ í›„ DB ì‹¤íŒ¨ ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(dag_file_path):
            os.remove(dag_file_path)
            logger.warning(f"ğŸ—‘ï¸ ì €ì¥ëœ íŒŒì¼ ì‚­ì œ: {dag_file_path}")
        raise HTTPException(status_code=500, detail=f"DAG creation failed. {e}")


@router.delete("/{dag_id}",
               response_model=APIResponse[DAGResponse],
               )
@api_response_wrapper
async def delete_dag(dag_id: str, db: Session = Depends(get_db)):
    """
    Delete a python DAG file
    :param dag_id:
    :param db:
    :return:
    """

    if not (dag_data := db.query(Flow).filter(Flow.id == dag_id).first()):
        return {"message": f"DAG {dag_id} not found"}
    dag_file_path = os.path.join(Config.DAG_DIR, f"{dag_id}.py")

    if not os.path.exists(dag_file_path):
        logger.warning(f"Warning: No file to delete {dag_file_path}")
    else:
        os.remove(dag_file_path)
        logger.warning(f"ğŸ—‘ï¸ ì €ì¥ëœ DAG íŒŒì¼ ì‚­ì œ: {dag_file_path}")

    db.query(Edge).filter(Edge.flow_id == dag_data.id).delete()
    db.query(Task).filter(Task.flow_id == dag_data.id).delete()
    db.delete(dag_data)
    db.commit()
    logger.warning(f"ğŸ—‘ï¸ DAG ë©”íƒ€ë°ì´í„° ì‚­ì œ: {dag_data}")

    return DAGResponse.from_dag(dag_data)


@router.get("",
            response_model=APIResponse[List[DAGResponse]],
            )
@api_response_wrapper
async def get_dag_list(db: Session = Depends(get_db)):
    """
    Get all available DAG
    :return:
    """
    logger.info(f"â–¶ï¸ DAG ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ")
    return [DAGResponse.from_dag(dag) for dag in db.query(Flow).all()]


@router.get("/{dag_id}",
            response_model=APIResponse[DAGResponse],
            )
@api_response_wrapper
async def get_dag(dag_id: str, db: Session = Depends(get_db)):
    """
    Get DAG
    :return:
    """
    logger.info(f"Get DAG {dag_id}")
    return DAGResponse.from_dag(db.query(Flow).filter(Flow.id == dag_id).first())
