import os
import pickle
import zipfile
from functools import wraps
from typing import Dict, List, Any


def xcom_decorator(inputs: List[Dict[str, Any]]):
    """airflow ê¸°ë³¸ ë°©ì‹ (64KB ì œí•œì´ ìˆìŒ)"""

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            from airflow.operators.python import get_current_context
            print(f"args: {args}, kwargs: {kwargs}")
            context = get_current_context()
            ti = context['ti']

            task = ti.task
            upstream_tasks = task.upstream_list
            downstream_tasks = task.downstream_list

            validated_inputs = {}
            if not upstream_tasks:
                print(f"â€¼ï¸ ì²˜ìŒ íƒœìŠ¤í¬ì„.")
                # ì •ì˜ëœ inpput ì •ë¦¬
                for inp in inputs:
                    key = inp["name"]
                    expected_type = inp["type"]
                    value = kwargs.get(key)
                    validated_inputs[key] = value
                # input_data = kwargs.get("input_data")
            else:
                print(f"ğŸ“Œ ì´ì „ íƒœìŠ¤í¬ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°")
                before_task_outputs = [
                    ti.xcom_pull(task_ids=t_id, key="output") for t_id in kwargs.get("before_task_ids", [])
                ]
                # xcomì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ validated_inputsì— ë°˜ì˜
                for i, inp in enumerate(inputs):
                    key = inp["name"]
                    if i < len(before_task_outputs):  # ë°ì´í„°ë¥¼ ìˆœì„œëŒ€ë¡œ ë§¤í•‘
                        validated_inputs[key] = before_task_outputs[i]

            result = func(*args, **validated_inputs)

            if not downstream_tasks:
                print(f"â€¼ï¸ ë§ˆì§€ë§‰ íƒœìŠ¤í¬ì„. output = {result}")
            else:
                print(f"ğŸ“Œ ê²°ê³¼ê°’ ì €ì¥")
                ti.xcom_push(key="output", value=result)
            return result

        return wrapper

    return decorator


def rabbitmq_decorator(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        return func(*args, **kwargs)

    return wrapper


def file_decorator(inputs: List[Dict[str, Any]]):
    def decorator(func):
        """íŒŒì¼ ê¸°ë°˜ ë°ì´í„° ì „ë‹¬ (ëŒ€ìš©ëŸ‰ ì§€ì›)"""
        # âœ… íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì • (Airflow ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ê³µìœ  ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •)
        base_dir = "/app/shared"
        os.makedirs(base_dir, exist_ok=True, mode=0o777)

        def get_input_data(dag_id, task_id, is_first_task, **kwargs):
            validated_inputs = {}
            if is_first_task:
                print(f"â€¼ï¸ ì²˜ìŒ íƒœìŠ¤í¬ ì‹¤í–‰: {dag_id} - {task_id}")
                # ì •ì˜ëœ inpput ì •ë¦¬
                for inp in inputs:
                    key = inp["name"]
                    expected_type = inp["type"]
                    value = kwargs.get(key)
                    validated_inputs[key] = value
            else:
                print(f"ğŸ“¥ {task_id} â†’ ì´ì „ Task ë°ì´í„° ë¡œë“œ ì¤‘...")
                before_task_outputs = []
                for t_id in kwargs.get("before_task_ids", []):
                    print(f"ğŸ“¥ ({t_id}) ë°ì´í„° ë¡œë“œ ì¤‘...")
                    prev_file_path = os.path.join(base_dir, dag_id, f"{t_id}.pkl")
                    if os.path.exists(prev_file_path):
                        with open(prev_file_path, "rb") as f:
                            before_task_outputs.append(pickle.load(f))
                    else:
                        print(f"âš ï¸ {prev_file_path} íŒŒì¼ ì—†ìŒ. ì´ì „ Task ì‹¤í–‰ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ.")
                for i, inp in enumerate(inputs):
                    key = inp["name"]
                    if i < len(before_task_outputs):  # ë°ì´í„°ë¥¼ ìˆœì„œëŒ€ë¡œ ë§¤í•‘
                        validated_inputs[key] = before_task_outputs[i]
            print(f"validated_inputs: {validated_inputs}")
            return validated_inputs

        def write_output_data(dag_id, task_id, is_last_task, output):
            dag_data_dir = os.path.join(base_dir, dag_id)
            os.makedirs(dag_data_dir, exist_ok=True, mode=0o777)
            file_path = os.path.join(dag_data_dir, f"{task_id}.pkl")
            # âœ… ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥
            with open(file_path, "wb") as f:
                pickle.dump(output, f)
            print(f"ğŸ“¥ {task_id} â†’ ê²°ê³¼ ì €ì¥: {file_path}")

            if is_last_task:
                print(f"â€¼ï¸ ë§ˆì§€ë§‰ íƒœìŠ¤í¬ ì™„ë£Œ: {task_id} â†’ output = {output}")

        @wraps(func)
        def wrapper(*args, **kwargs):
            print(args, kwargs)
            if kwargs.get("operator_type") == "python":
                from airflow.operators.python import get_current_context
                context = get_current_context()
                ti = context['ti']

                dag_id = ti.dag_id
                task_id = ti.task.task_id
                is_first_task = len(list(ti.task.upstream_list)) == 0
                is_last_task = len(list(ti.task.downstream_list)) == 0
            else:
                dag_id = kwargs.pop("dag_id")
                task_id = kwargs.pop("task_id")
                is_first_task = kwargs.pop("is_first_task", "True") == "True"
                is_last_task = kwargs.pop("is_last_task", "True") == "True"

            input_data = get_input_data(dag_id, task_id, is_first_task, **kwargs)
            # âœ… ì‹¤ì œ UDF ì‹¤í–‰
            kwargs.update(input_data)
            result = func(*args, **kwargs)
            write_output_data(dag_id, task_id, is_last_task, result)

            return result

        return wrapper

    return decorator


def zip_executable_udf(udf_dir: str, udf_name: str):
    source_path = os.path.join(udf_dir, udf_name)  # ì••ì¶•í•  í´ë”
    zip_path = os.path.join(udf_dir, udf_name, f"{udf_name}.zip")  # ì €ì¥í•  ZIP íŒŒì¼ ê²½ë¡œ

    # ğŸ”¹ ZIP íŒŒì¼ ìƒì„±
    with zipfile.ZipFile(zip_path, "w") as zipf:
        for root, _, files in os.walk(source_path):
            for file in files:
                file_path = os.path.join(root, file)
                arcname = os.path.relpath(file_path, source_path)  # ZIP ë‚´ë¶€ ê²½ë¡œ ìœ ì§€
                zipf.write(file_path, arcname)

    print(f"âœ… ZIP íŒŒì¼ ìƒì„± ì™„ë£Œ: {zip_path}")


# ğŸ”¹ UDF ì‹¤í–‰ í•¨ìˆ˜ (ZIP íŒŒì¼ ì‚¬ìš©)
def execute_udf(udf_name, main_filename, function_name, *args, **kwargs):
    import os
    import sys
    import zipfile
    udf_dir = "/opt/airflow/udfs"
    zip_path = os.path.join(udf_dir, udf_name, f"{udf_name}.zip")
    extract_path = f"/tmp/{udf_name}"

    # ğŸ”¹ ZIP íŒŒì¼ í•´ì œ (UDF íŒŒì¼ì€ ìœ ì§€ë¨)
    with zipfile.ZipFile(zip_path, "r") as zipf:
        zipf.extractall(extract_path)

    # ğŸ”¹ Python ê²½ë¡œ ì¶”ê°€ (UDF ì‹¤í–‰ ê°€ëŠ¥)
    sys.path.append(extract_path)

    # ğŸ”¹ ë©”íƒ€ë°ì´í„° ì¡°íšŒí•˜ì—¬ ì…ë ¥ê°’ ì ìš©
    # from example_udf_fetch_64a6ca import run
    module = __import__(f"{udf_name}.{main_filename}", fromlist=[function_name])
    udf_function = getattr(module, function_name, None)
    return udf_function(*args, **kwargs)


def wrapped_callable(*args, **kwargs):
    from utils.decorator import file_decorator, execute_udf
    decorated_func = file_decorator(
        inputs=[{"name": "url", "type": "string"}]
    )(execute_udf)
    return decorated_func(*args, **kwargs)
